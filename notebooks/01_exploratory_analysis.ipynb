{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# NYC Crash Risk Prediction - Exploratory Data Analysis\n",
                "\n",
                "Comprehensive analysis of the NYC vehicle collision dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from datetime import datetime\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "plt.rcParams['font.size'] = 11\n",
                "\n",
                "pd.set_option('display.max_columns', 50)\n",
                "pd.set_option('display.float_format', lambda x: f'{x:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load processed dataset (sample for EDA)\n",
                "SAMPLE_SIZE = 100_000\n",
                "\n",
                "df = pd.read_csv('../data/processed/train.csv', parse_dates=['hour'])\n",
                "df_sample = df.sample(n=min(SAMPLE_SIZE, len(df)), random_state=42)\n",
                "\n",
                "print(f\"Total records: {len(df):,}\")\n",
                "print(f\"Sample size: {len(df_sample):,}\")\n",
                "print(f\"Date range: {df['hour'].min()} to {df['hour'].max()}\")\n",
                "print(f\"Unique hexagons: {df['h3_index'].nunique():,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sample.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_sample.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Target Variable Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "# Distribution\n",
                "axes[0].hist(df_sample['accident_count'], bins=50, alpha=0.7, color='steelblue', edgecolor='white')\n",
                "axes[0].set_xlabel('Accident Count')\n",
                "axes[0].set_ylabel('Frequency')\n",
                "axes[0].set_title('Distribution of Accident Count')\n",
                "axes[0].axvline(df_sample['accident_count'].mean(), color='red', linestyle='--', label=f\"Mean: {df_sample['accident_count'].mean():.2f}\")\n",
                "axes[0].legend()\n",
                "\n",
                "# Log distribution\n",
                "log_counts = np.log1p(df_sample['accident_count'])\n",
                "axes[1].hist(log_counts, bins=50, alpha=0.7, color='green', edgecolor='white')\n",
                "axes[1].set_xlabel('Log(1 + Accident Count)')\n",
                "axes[1].set_ylabel('Frequency')\n",
                "axes[1].set_title('Log-Transformed Distribution')\n",
                "\n",
                "# Zero vs non-zero\n",
                "zero_pct = (df_sample['accident_count'] == 0).mean() * 100\n",
                "axes[2].pie([zero_pct, 100-zero_pct], labels=['No Accidents', 'Has Accidents'], \n",
                "            autopct='%1.1f%%', colors=['lightgreen', 'coral'])\n",
                "axes[2].set_title('Zero-Inflation Analysis')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/eda_target_distribution.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Target Variable Statistics:\")\n",
                "print(f\"  Mean: {df_sample['accident_count'].mean():.4f}\")\n",
                "print(f\"  Median: {df_sample['accident_count'].median():.4f}\")\n",
                "print(f\"  Std: {df_sample['accident_count'].std():.4f}\")\n",
                "print(f\"  Max: {df_sample['accident_count'].max():.0f}\")\n",
                "print(f\"  Zero-inflation: {(df_sample['accident_count'] == 0).mean()*100:.2f}%\")\n",
                "print(f\"  Skewness: {df_sample['accident_count'].skew():.4f}\")\n",
                "print(f\"  Kurtosis: {df_sample['accident_count'].kurtosis():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Temporal Patterns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "# Hourly pattern\n",
                "hourly = df_sample.groupby('hour_of_day')['accident_count'].mean()\n",
                "axes[0, 0].bar(hourly.index, hourly.values, color='steelblue', edgecolor='white')\n",
                "axes[0, 0].set_xlabel('Hour of Day')\n",
                "axes[0, 0].set_ylabel('Mean Accident Count')\n",
                "axes[0, 0].set_title('Hourly Pattern')\n",
                "axes[0, 0].set_xticks(range(0, 24, 2))\n",
                "\n",
                "# Daily pattern\n",
                "day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
                "daily = df_sample.groupby('day_of_week')['accident_count'].mean()\n",
                "colors = ['steelblue']*5 + ['coral']*2\n",
                "axes[0, 1].bar(day_names, daily.values, color=colors, edgecolor='white')\n",
                "axes[0, 1].set_xlabel('Day of Week')\n",
                "axes[0, 1].set_ylabel('Mean Accident Count')\n",
                "axes[0, 1].set_title('Daily Pattern (Weekend in red)')\n",
                "\n",
                "# Monthly pattern\n",
                "monthly = df_sample.groupby('month')['accident_count'].mean()\n",
                "axes[1, 0].plot(monthly.index, monthly.values, 'o-', color='green', linewidth=2, markersize=8)\n",
                "axes[1, 0].set_xlabel('Month')\n",
                "axes[1, 0].set_ylabel('Mean Accident Count')\n",
                "axes[1, 0].set_title('Monthly Pattern')\n",
                "axes[1, 0].set_xticks(range(1, 13))\n",
                "\n",
                "# Weekend vs Weekday\n",
                "grouping = df_sample.groupby(['hour_of_day', 'is_weekend'])['accident_count'].mean().unstack()\n",
                "grouping.columns = ['Weekday', 'Weekend']\n",
                "grouping.plot(ax=axes[1, 1], style=['o-', 's-'], linewidth=2, markersize=6)\n",
                "axes[1, 1].set_xlabel('Hour of Day')\n",
                "axes[1, 1].set_ylabel('Mean Accident Count')\n",
                "axes[1, 1].set_title('Weekday vs Weekend Hourly Pattern')\n",
                "axes[1, 1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/eda_temporal_patterns.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Weather Impact Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "weather_cols = ['temperature', 'precipitation', 'wind_speed', 'snow_depth']\n",
                "\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "for idx, col in enumerate(weather_cols):\n",
                "    ax = axes[idx // 2, idx % 2]\n",
                "    \n",
                "    # Bin the weather variable\n",
                "    df_sample[f'{col}_bin'] = pd.qcut(df_sample[col], q=10, duplicates='drop')\n",
                "    grouped = df_sample.groupby(f'{col}_bin')['accident_count'].mean()\n",
                "    \n",
                "    ax.bar(range(len(grouped)), grouped.values, color='teal', edgecolor='white')\n",
                "    ax.set_xlabel(col.replace('_', ' ').title())\n",
                "    ax.set_ylabel('Mean Accident Count')\n",
                "    ax.set_title(f'Accident Count vs {col.replace(\"_\", \" \").title()}')\n",
                "    ax.set_xticks(range(len(grouped)))\n",
                "    ax.set_xticklabels([f'Q{i+1}' for i in range(len(grouped))], rotation=45)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/eda_weather_impact.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation analysis\n",
                "corr_cols = ['accident_count', 'temperature', 'precipitation', 'wind_speed', \n",
                "             'snow_depth', 'hour_of_day', 'day_of_week', 'month',\n",
                "             'accidents_1h_ago', 'accidents_24h_ago', 'rolling_mean_7d']\n",
                "\n",
                "corr_matrix = df_sample[corr_cols].corr()\n",
                "\n",
                "plt.figure(figsize=(12, 10))\n",
                "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
                "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.3f', cmap='RdBu_r', \n",
                "            center=0, square=True, linewidths=0.5)\n",
                "plt.title('Feature Correlation Matrix', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/eda_correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Spatial Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hexagon-level statistics\n",
                "hex_stats = df.groupby('h3_index').agg({\n",
                "    'accident_count': ['mean', 'std', 'sum', 'count']\n",
                "}).reset_index()\n",
                "hex_stats.columns = ['h3_index', 'mean_accidents', 'std_accidents', 'total_accidents', 'n_records']\n",
                "\n",
                "print(f\"Hexagon Statistics:\")\n",
                "print(f\"  Total hexagons: {len(hex_stats):,}\")\n",
                "print(f\"  Mean accidents per hexagon: {hex_stats['mean_accidents'].mean():.4f}\")\n",
                "print(f\"  Std accidents per hexagon: {hex_stats['mean_accidents'].std():.4f}\")\n",
                "print(f\"  Top 10 hotspots account for: {hex_stats.nlargest(10, 'total_accidents')['total_accidents'].sum() / hex_stats['total_accidents'].sum() * 100:.1f}% of accidents\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Distribution of hexagon average accidents\n",
                "axes[0].hist(hex_stats['mean_accidents'], bins=50, alpha=0.7, color='purple', edgecolor='white')\n",
                "axes[0].set_xlabel('Mean Accident Count per Hexagon')\n",
                "axes[0].set_ylabel('Frequency')\n",
                "axes[0].set_title('Distribution of Hexagon Risk Levels')\n",
                "axes[0].axvline(hex_stats['mean_accidents'].median(), color='red', linestyle='--', \n",
                "                label=f\"Median: {hex_stats['mean_accidents'].median():.4f}\")\n",
                "axes[0].legend()\n",
                "\n",
                "# Top 20 hotspots\n",
                "top_20 = hex_stats.nlargest(20, 'mean_accidents')\n",
                "axes[1].barh(range(20), top_20['mean_accidents'].values, color='coral')\n",
                "axes[1].set_yticks(range(20))\n",
                "axes[1].set_yticklabels([f\"{h[:8]}...\" for h in top_20['h3_index']])\n",
                "axes[1].set_xlabel('Mean Accident Count')\n",
                "axes[1].set_title('Top 20 Hotspot Hexagons')\n",
                "axes[1].invert_yaxis()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/eda_spatial_analysis.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Lag Features Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "# Accidents 1h ago vs current\n",
                "axes[0].scatter(df_sample['accidents_1h_ago'], df_sample['accident_count'], alpha=0.1, s=5)\n",
                "axes[0].set_xlabel('Accidents 1h Ago')\n",
                "axes[0].set_ylabel('Current Accidents')\n",
                "axes[0].set_title('Autocorrelation: 1-Hour Lag')\n",
                "\n",
                "# Accidents 24h ago vs current\n",
                "axes[1].scatter(df_sample['accidents_24h_ago'], df_sample['accident_count'], alpha=0.1, s=5)\n",
                "axes[1].set_xlabel('Accidents 24h Ago')\n",
                "axes[1].set_ylabel('Current Accidents')\n",
                "axes[1].set_title('Autocorrelation: 24-Hour Lag')\n",
                "\n",
                "# Rolling mean vs current\n",
                "axes[2].scatter(df_sample['rolling_mean_7d'], df_sample['accident_count'], alpha=0.1, s=5)\n",
                "axes[2].set_xlabel('7-Day Rolling Mean')\n",
                "axes[2].set_ylabel('Current Accidents')\n",
                "axes[2].set_title('Rolling Average Correlation')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/eda_lag_features.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Key Insights Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"KEY INSIGHTS FROM EXPLORATORY DATA ANALYSIS\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Target insights\n",
                "zero_rate = (df_sample['accident_count'] == 0).mean() * 100\n",
                "print(f\"\\n1. TARGET VARIABLE:\")\n",
                "print(f\"   - Highly zero-inflated: {zero_rate:.1f}% of records have zero accidents\")\n",
                "print(f\"   - Strong positive skew ({df_sample['accident_count'].skew():.2f})\")\n",
                "print(f\"   - Poisson/Count regression is appropriate\")\n",
                "\n",
                "# Temporal insights\n",
                "peak_hour = df_sample.groupby('hour_of_day')['accident_count'].mean().idxmax()\n",
                "low_hour = df_sample.groupby('hour_of_day')['accident_count'].mean().idxmin()\n",
                "print(f\"\\n2. TEMPORAL PATTERNS:\")\n",
                "print(f\"   - Peak risk hour: {peak_hour}:00\")\n",
                "print(f\"   - Lowest risk hour: {low_hour}:00\")\n",
                "print(f\"   - Weekend vs Weekday: marginal difference\")\n",
                "\n",
                "# Weather insights\n",
                "precip_corr = df_sample['precipitation'].corr(df_sample['accident_count'])\n",
                "temp_corr = df_sample['temperature'].corr(df_sample['accident_count'])\n",
                "print(f\"\\n3. WEATHER IMPACT:\")\n",
                "print(f\"   - Precipitation correlation: {precip_corr:.4f}\")\n",
                "print(f\"   - Temperature correlation: {temp_corr:.4f}\")\n",
                "print(f\"   - Weather has moderate predictive power\")\n",
                "\n",
                "# Spatial insights\n",
                "top_10_pct = hex_stats.nlargest(10, 'total_accidents')['total_accidents'].sum() / hex_stats['total_accidents'].sum() * 100\n",
                "print(f\"\\n4. SPATIAL PATTERNS:\")\n",
                "print(f\"   - Top 10 hexagons: {top_10_pct:.1f}% of all accidents\")\n",
                "print(f\"   - Strong spatial concentration\")\n",
                "print(f\"   - Spatial features will be important\")\n",
                "\n",
                "# Lag features\n",
                "lag_1h_corr = df_sample['accidents_1h_ago'].corr(df_sample['accident_count'])\n",
                "rolling_corr = df_sample['rolling_mean_7d'].corr(df_sample['accident_count'])\n",
                "print(f\"\\n5. LAG FEATURES:\")\n",
                "print(f\"   - 1-hour lag correlation: {lag_1h_corr:.4f}\")\n",
                "print(f\"   - 7-day rolling mean correlation: {rolling_corr:.4f}\")\n",
                "print(f\"   - Historical patterns are strong predictors\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}